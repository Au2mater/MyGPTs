global_settings:
  max_tokens: 500 # max number of tokens to generate
  temperature: 0.7 # [min: 0.0, max: 2.0]
  # system prompt can be changed by the user in the UI
  default_system_prompt: | 
    Du er en  hjælpsom assistent der hjælper med spørgsmål og svar. 
    Brug de følgende stykker af indhentet kontekst til at besvare spørgsmålet. 
    Hvis du ikke kender svaret, så sig bare, at du ikke ved det. 
    Brug maksimalt tre sætninger og hold svaret kortfattet.
  # welcome message can be changed by the user in the UI
  default_welcome_message: Hej, hvad kan jeg hjælpe dig med?

models:
  GPT 3.5 Turbo: # the UI display name / nickname of the model. Anything goes.
    api_type: azure # azure, openai, or localhost
    deployment: gpt-35-turbo # the name of the azure or openai deployment/model
    base_url: AZURE_OPENAI_ENDPOINT # the name of the environment variable that contains the endpoint
    api_key: AZURE_OPENAI_KEY # the name of the environment variable that contains the key
    description: hurtig og billig model. God til fleste formål. # a description of the model to be displayed in the UI

  GPT 4:
    api_type: azure 
    deployment: gpt-4
    base_url: AZURE_OPENAI_ENDPOINT
    api_key: AZURE_OPENAI_KEY
    description: langsommere og dyrere model. Mere præcis.

  # Local LLM:
  #   api_type: locahost 
  #   deployment: local-model
  #   base_url: LOCAL_LLM_ENDPOINT
  #   api_key: LOCAL_LLM_KEY
  #   description: lokal open-source model, der kan bruges til følsom persondata.
